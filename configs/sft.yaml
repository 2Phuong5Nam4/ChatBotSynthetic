# SFT Training Configuration for Heineken Vietnam Chatbot

# Model Configuration
model:
  name: "unsloth/Qwen3-8B"  # or "unsloth/Llama-3.2-1B-Instruct"
  max_seq_length: 2048
  dtype: null  # null for auto detection, float16 for Tesla T4/V100, bfloat16 for Ampere+
  load_in_4bit: true
  token: null  # HuggingFace token if using gated models

# LoRA Configuration
lora:
  r: 16  # LoRA rank - higher = more parameters (8, 16, 32, 64, 128)
  lora_alpha: 16
  lora_dropout: 0  # 0 is optimized
  bias: "none"  # "none" is optimized
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  use_gradient_checkpointing: "unsloth"  # true or "unsloth" for long context
  random_state: 3407
  use_rslora: false
  loftq_config: null

# Chat Template
chat_template: "qwen3-thinking"

# Dataset Configuration
dataset:
  train_path: "data/train.jsonl"
  validation_path: "data/validation.jsonl"
  format: "json"
  text_field: "text"
  message_field: "messages"

# Training Configuration
training:
  output_dir: "checkpoints"
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  warmup_steps: 5
  max_steps: 30
  num_train_epochs: null  # Set this for full training run instead of max_steps
  learning_rate: 2.0e-4
  logging_steps: 1
  optim: "adamw_8bit"
  weight_decay: 0.001
  lr_scheduler_type: "linear"
  seed: 3407
  report_to: "none"  # Options: "wandb", "tensorboard", "none"
  save_steps: 10
  save_total_limit: 3
  packing: false  # Can make training 5x faster for short sequences

# Response-only Training
response_only_training:
  enabled: true
  instruction_part: "<|start_header_id|>user<|end_header_id|>\n\n"
  response_part: "<|start_header_id|>assistant<|end_header_id|>\n\n"

# Inference Configuration
inference:
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  do_sample: true

# Model Saving
save:
  method: "merged_16bit"  # Options: "lora", "merged_16bit", "merged_4bit", "gguf"
  save_path: "checkpoints/final_model"
  push_to_hub: false
  hub_model_id: null  # e.g., "your-username/heineken-chatbot"
  hub_token: null

# Monitoring
monitoring:
  show_memory_stats: true
  log_training_stats: true
